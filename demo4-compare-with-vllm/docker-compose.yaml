version: '3.8'
services:
  lmcache_server:
    image: lmcache/lmcache_vllm:lmcache-0.1.3
    entrypoint: ["lmcache_server"]
    command: "0.0.0.0 65432"
    ports:
      - "65432:65432"
    environment:
      HF_TOKEN: ${HF_TOKEN}
      LMCACHE_CONFIG_FILE: /etc/lmcache-config.yaml

  lmcache_0:
    image: lmcache/lmcache_vllm:lmcache-0.1.3
    command: "${MODEL} --gpu-memory-utilization 0.6 --port 8000"
    ports:
      - "8000:8000"
    depends_on:
      - lmcache_server
    environment:
      HF_TOKEN: ${HF_TOKEN}
      LMCACHE_CONFIG_FILE: /etc/lmcache-config.yaml
    volumes:
      - ${LOCAL_HF_HOME}:/root/.cache/huggingface
      - ./lmcache-config.yaml:/etc/lmcache-config.yaml
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              device_ids: ['0']
    ipc: host

  lmcache_1:
    image: lmcache/lmcache_vllm:lmcache-0.1.3
    command: "${MODEL} --gpu-memory-utilization 0.6 --port 8001"
    ports:
      - "8001:8001"
    depends_on:
      - lmcache_server
    environment:
      HF_TOKEN: ${HF_TOKEN}
      LMCACHE_CONFIG_FILE: /etc/lmcache-config.yaml
    volumes:
      - ${LOCAL_HF_HOME}:/root/.cache/huggingface
      - ./lmcache-config.yaml:/etc/lmcache-config.yaml
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              device_ids: ['1']
    ipc: host

  vllm_0:
    image: vllm/vllm-openai:v0.6.2
    command: "--model ${MODEL} --gpu-memory-utilization 0.6 --port 8002"
    ports:
      - "8002:8002"
    environment:
      HF_TOKEN: ${HF_TOKEN}
    volumes:
      - ${LOCAL_HF_HOME}:/root/.cache/huggingface
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              device_ids: ['2']
    ipc: host

  vllm_1:
    image: vllm/vllm-openai:v0.6.2
    command: "--model ${MODEL} --gpu-memory-utilization 0.6 --port 8003"
    ports:
      - "8003:8003"
    environment:
      HF_TOKEN: ${HF_TOKEN}
    volumes:
      - ${LOCAL_HF_HOME}:/root/.cache/huggingface
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              device_ids: ['3']
    ipc: host
